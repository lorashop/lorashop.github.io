<!DOCTYPE html>
<html>
    <head>
        <meta charset="utf-8">
        <meta name="description"
        content="LoRAShop is a multi-concept composition method for image generation and editing.">
        <meta name="keywords" content="Diffusion Models, Latent Space Exploration">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <title>LoRAShop</title>
        <script src="https://www.w3counter.com/tracker.js?id=155741"></script>
        <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
        dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'G-PYVRSFMDRL');
        </script>

    <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css">
    <link rel="stylesheet" href="./static/css/bulma.min.css">
    <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
    <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
    <link rel="stylesheet" href="./static/css/font-awesome.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
    <link rel="stylesheet" href="./static/css/index.css">
    <link rel="stylesheet" href="https://unpkg.com/aos@next/dist/aos.css" />

    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
    <script defer src="./static/js/fontawesome.all.min.js"></script>
    <script src="./static/js/bulma-carousel.min.js"></script>
    <script src="./static/js/bulma-slider.min.js"></script>
    <script src="./static/js/index.js"></script>
    </head>

    <body>
        <!-- Navigation Bar -->
        <nav class="navbar is-fixed-top is-light" role="navigation" aria-label="main navigation">
            <div class="container">
                <div class="navbar-brand">
                    <a class="navbar-item" href="#top">
                        <strong class="is-size-4">LoRAShop</strong>
                    </a>
                    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
                        <span aria-hidden="true"></span>
                        <span aria-hidden="true"></span>
                        <span aria-hidden="true"></span>
                    </a>
                </div>
                <div class="navbar-menu">
                    <div class="navbar-end">
                        <a class="navbar-item" href="#abstract">Abstract</a>
                        <a class="navbar-item" href="#method">Method</a>
                        <a class="navbar-item" href="#results">Results</a>
                        <a class="navbar-item" href="#BibTeX">BibTeX</a>
                    </div>
                </div>
            </div>
        </nav>

        <section class="hero is-light" id="top">
            <div class="hero-body">
              <div class="container is-max-desktop">
                <div class="columns is-centered">
                  <div class="column has-text-centered">
                    <h1 class="title is-1 publication-title" data-aos="fade-up">LoRAShop: Training-Free Multi-Concept Image Generation and Editing with Rectified Flow Transformers</h1>
                    <div class="is-size-5 publication-authors" data-aos="fade-up" data-aos-delay="100">
                      <span class="author-block">
                        <a href="https://yusufdalva.github.io/">Yusuf Dalva</a>,</span>
                        <span class="author-block">
                            <a href="https://yesiltepe-hidir.github.io/">Hidir Yesiltepe</a>,</span>
                      <span class="author-block">
                        <a href="https://pinguar.org/">Pinar Yanardag</a>
                      </span>
                    </div>
          
                    <div class="is-size-5 publication-authors" data-aos="fade-up" data-aos-delay="150">
                      <span class="author-block">Virginia Tech</span>
                    </div>

                    <div class="column has-text-centered" data-aos="fade-up" data-aos-delay="200">
                        <div class="publication-links">
      
                          <span class="link-block">
                            <a href="https://arxiv.org/abs/2412.09611"
                               class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                  <i class="fas fa-file-pdf"></i>
                              </span>
                              <span>Paper</span>
                            </a>
                          </span>
      
                          <span class="link-block">
                            <a href=""
                               class="external-link button is-normal is-rounded is-dark">
                              <span class="icon">
                                  <i class="fab fa-github"></i>
                              </span>
                              <span>Code (coming soon)</span>
                              </a>
                          </span>
                        </div>
                    </div>
                </div>
              </div>
            </div>
          </div>
        </section>

        <section class="hero teaser" data-aos="fade-up">
            <div class="container is-max-desktop">
              <div class="hero-body">
                <h4 class="subtitle">
                    <br>
                    <b>TL;DR</b> We propose a training-freeimage editing and generation method with personalized concepts. In inference time, 
                    we combine LoRA adapters trained for different subjects, with non-overlapping subject priors.
                    <!--
                    <span class="dnerf">NoiseCLR</span> discovers semantic directions in latent diffusion models in a completely unsupervised manner. 
                    With this work, we present latent directions discovered in domains such as Art, Fashion, Face, Cats and Cars in Stable Diffusion. -->
                </h4>
                <div class="container">
                    <img src="./static/images/teaser_arxiv.png" alt="LoRAShop Teaser" />
                    <br/>
                    <p>
                      We present LoRAShop, a training-free framework enabling the simultaneous use of multiple LoRA adapters for generation and editing. 
                      By identifying the coarse boundaries of personalized concepts as subject priors, we allow the use of multiple LoRA adapters by eliminating 
                      the "cross-talk" between different adapters.
                    </p>
                </div>
            </div>
        </section>

        <section class="section hero is-light" id="abstract" data-aos="fade-up">
            <div class="container is-max-desktop">
              <!-- Abstract. -->
              <div class="columns is-centered has-text-centered">
                <div class="column is-four-fifths">
                  <h2 class="title is-3">Abstract</h2>
                  <div class="content has-text-justified">
                    <p>
                      We introduce LoRAShop, the first framework for multi-concept image editing with LoRA models. LoRAShop builds on a key observation about 
                      the feature interaction patterns inside Flux-style diffusion transformers: concept-specific transformer features activate spatially coherent 
                      regions early in the denoising process. We harness this observation to derive a disentangled latent mask for each concept in a prior forward pass 
                      and blend the corresponding LoRA weights only within regions bounding the concepts to be personalized. The resulting edits seamlessly integrate 
                      multiple subjects or styles into the original scene while preserving global context, lighting, and fine details. Our experiments  demonstrate 
                      that LoRAShop delivers better identity preservation compared to baselines. By eliminating retraining and external constraints, LoRAShop turns 
                      personalized diffusion models into a practical `photoshop-with-LoRAs' tool and opens new avenues for compositional visual storytelling and rapid 
                      creative iteration.
                    </p>
                  </div>
                </div>
              </div>
        </section>

        <section class="section" id="method" data-aos="fade-up">
            <div class="container is-max-desktop">
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
                  <h2 class="title is-3">Method</h2>
        
                  <div class="content has-text-justified">
                    <!--
                    <p>
                     Explain method
                    </p>
                  -->
                    <div class="container">
                      <img src="./static/images/framework.png" alt="LoRAShop Framework" />
                      <br />
                    </div>
        
                    <p>
                      LoRAShop enables multi-subject generation and editing over a two-stage training-free pipeline. First, we extract the subject prior <b>M&#770;<sub>c'</sub></b>, 
                      which gives a coarse-level prior on where the concept of interest, <b>c'</b>, is located. Following, we introduce a blending mechanism over the transformer
                       block residuals, which both enables seamless blending of customized features and bounds the region-of-interest for the LoRA adapter utilized.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </section>

          <section class="section" data-aos="fade-up">
            <div class="container is-max-desktop">
                <h1 class="title is-3 has-text-centered">Extraction of Subject Priors</h1>
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
        
                  <div class="content has-text-justified">
                    <!--
                    <p>
                     Explain method
                    </p>
                  -->
                    <div class="container">
                      <img src="./static/images/block_motivation.png" alt="Block Motivation" />
                      <br />
                    </div>
                    <p>
                        Upon investigation of transformer blocks, we observe that the last double-stream block of FLUX provides text-image attention maps, that can separate 
                        different entities effectively.
                    </p>
                </div>
              </div>
            </div>
          </section>
              
        
          <section class="section" id="results" data-aos="fade-up">
            <div class="container is-max-desktop">
                <h1 class="title is-3 has-text-centered">Editing Results</h1>
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
        
                  <div class="content has-text-justified">
                  <h4 class="title is-4 has-text-centered">Personalized Editing with Single/Multiple Concepts</h4>
                    <div class="carousel-container">
                      <!-- Start Carousel -->
                      <div class="carousel">
                        <div class="item">
                          <figure class="image">
                            <img src="./static/images/main_results.png" alt="Main Results - Slide 1" />
                            <figcaption class="has-text-centered mt-2">
                            </figcaption>
                          </figure>
                        </div>
                        <div class="item">
                          <figure class="image">
                            <img src="./static/images/face_swap_1.png" alt="Main Results - Slide 2" />
                            <figcaption class="has-text-centered mt-2">
                            </figcaption>
                          </figure>
                        </div>
                        <div class="item">
                          <figure class="image">
                            <img src="./static/images/face_swap_2.png" alt="Main Results - Slide 3" />
                            <figcaption class="has-text-centered mt-2">
                            </figcaption>
                          </figure>
                        </div>
                      </div>
                      <!-- End Carousel -->
                      <div class="carousel-navigation">
                        <div class="carousel-nav-left">
                          <i class="fas fa-chevron-left"></i>
                        </div>
                        <div class="carousel-nav-right">
                          <i class="fas fa-chevron-right"></i>
                        </div>
                      </div>
                    </div>
                    <p>
                        Over real/generated images, our method is able to target the individual concepts, and able to perform the desired personalized edits on them.
                    </p>
                </div>
              </div>
            </div>
          </section>

          <section class="section" data-aos="fade-up">
            <div class="container is-max-desktop">
                <h1 class="title is-3 has-text-centered">Generation with Multiple Concepts</h1>
              <div class="columns is-centered has-text-centered">
                <div class="column is-12">
        
                  <div class="content has-text-justified">
                    <div class="carousel-container">
                      <!-- Start Carousel -->
                      <div class="carousel" id="generation-carousel">
                        <div class="item">
                          <figure class="image">
                            <img src="./static/images/four_subject.png" alt="Four Subject Generation" />
                            <figcaption class="has-text-centered mt-2">
                              <h4 class="title is-5">Generation with Four Concepts</h4>
                            </figcaption>
                          </figure>
                        </div>
                        <div class="item">
                          <figure class="image">
                            <img src="./static/images/three_subject.png" alt="Three Subject Generation" />
                            <figcaption class="has-text-centered mt-2">
                              <h4 class="title is-5">Generation with Three Concepts</h4>
                            </figcaption>
                          </figure>
                        </div>
                        <div class="item">
                          <figure class="image">
                            <img src="./static/images/objects.png" alt="Object Generation" />
                            <figcaption class="has-text-centered mt-2">
                              <h4 class="title is-5">Generation with Concepts from Different Domains</h4>
                            </figcaption>
                          </figure>
                        </div>
                      </div>
                      <!-- End Carousel -->
                      <div class="carousel-navigation">
                        <div class="carousel-nav-left">
                          <i class="fas fa-chevron-left"></i>
                        </div>
                        <div class="carousel-nav-right">
                          <i class="fas fa-chevron-right"></i>
                        </div>
                      </div>
                    </div>
                    <p class="has-text-centered mt-4">
                      In addition to editing, our method is able to perform generation with multiple personalized concepts, which can be the same kind (e.g. person) or different (e.g. person and clothing).
                    </p>
                </div>
              </div>
            </div>
          </section>

          <section class="section" id="BibTeX" data-aos="fade-up">
            <div class="container is-max-desktop content">
              <h2 class="title is-3">BibTeX</h2>
              <pre><code>
TBD
              </code></pre>
            </div>
          </section>

          <footer class="footer">
            <div class="container">
              <div class="content has-text-centered is-centered">
                <a class="icon-link" href="https://github.com/yusufdalva" class="external-link" disabled>
                  <i class="fab fa-github"></i>
                </a>
              </div>
              <div class="columns">
                <div class="column is-8">
                  <div class="content has-text-justified">
                    <!-- <p>
                      This website is licensed under a <a rel="license"
                                                          href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
                      Commons Attribution-ShareAlike 4.0 International License</a>.
                    </p> -->
                    <p>This page is adapted from <a
                        href="https://github.com/nerfies/nerfies.github.io">this</a> implementation.
                    </p>
                  </div>
                </div>
              </div>
            </div>
          </footer>

          <!-- Back to top button -->
          <div class="back-to-top" id="back-to-top">
            <a href="#top"><i class="fas fa-arrow-up"></i></a>
          </div>

          <!-- AOS Animation Library -->
          <script src="https://unpkg.com/aos@next/dist/aos.js"></script>
          <script>
            // Initialize AOS animations
            AOS.init({
              duration: 800,
              once: true
            });

            // Ensure page is fully loaded before initializing carousels
            window.addEventListener('load', function() {
              // This will be called after everything is loaded
              console.log('Page fully loaded, initializing carousels');
              
              // Reinitialize carousels if needed
              if (typeof bulmaCarousel !== 'undefined') {
                // Additional initialization can be placed here if needed
                console.log('Bulma carousel is available');
              }
            });

            // Mobile menu toggle
            document.addEventListener('DOMContentLoaded', () => {
              const $navbarBurgers = Array.prototype.slice.call(document.querySelectorAll('.navbar-burger'), 0);
              if ($navbarBurgers.length > 0) {
                $navbarBurgers.forEach( el => {
                  el.addEventListener('click', () => {
                    const target = el.dataset.target || el.getAttribute('aria-controls');
                    const $target = document.getElementById(target) || el.parentElement.nextElementSibling;
                    el.classList.toggle('is-active');
                    $target.classList.toggle('is-active');
                  });
                });
              }

              // Back to top button
              const backToTopButton = document.getElementById('back-to-top');
              window.addEventListener('scroll', () => {
                if (window.pageYOffset > 300) {
                  backToTopButton.style.display = 'block';
                } else {
                  backToTopButton.style.display = 'none';
                }
              });
            });
          </script>
    </body>
</html>